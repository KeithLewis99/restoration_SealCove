---
title: "ReadMe"
author: "Keith Lewis"
date: "`r Sys.Date()`"
output: html_document
---
<style type="text/css">
    div.datatables { height: auto !important;}
</style>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
library(xtable)
library(magrittr)
library(DT)
tab1 <- read.csv("Raw data/glmm_comparison.csv")
```

# Explanation

- Kristen Loughlin wrote all the files in these folders with the exception of the "amec.efishingX.r" files and which are functions to estimate biomass and density based on depletion and the files in folder "R files" which are from Dave Cote.  The estimates from "amec.efishingX.r" are then scaled by area within the function so no need for post-processing.  
- I added glmm_data.R, glmm_biomass_models.R, glmm_density_models.R,  glmm_anova.R, glmm_fun.R, and teh scratch_pad_*.R files


## Biomass and Density
- Kristen took the raw data and ran these by year through the amec function to get scaled biomass and density.  I have a file called 'scratch_pad.R' where I run the function (after running the function first) for a given data file.  All of these data files are in the file "kristin" and are named "sealcoveYEARBYxxxx", e.g., seacove1988bysite.csv.  

- I then put the results from scratch_pad.R in folder "output" after renaming them.  Kristin is pretty sure that she did something similar but collated them into files that are in folder "CS_Estimates" and in the files "output_cs_eachssppbysite.xlsx and output_cs_salmonids_bysite.xlsx.  The csv files in this folder are derived from these files (check this) and these files are generally used in all the R files in the main folder. E.g. "edited_cs_estimates_by_site" is an r object that was generated from "edited_cs_estimates_by_site.csv" (a coallated file).

- I ran "edited_cs_estimates_by_site.csv" through "amec.efishingcs.r" and got the exact same values as Kristen for 2015 and 2016 although it appears that she used the "stand.trad.species.biomass.contributions
" formulation (see file "edited_cs_estimates_by_site.csv" in folder "CS_Estimates" and file "e.fishing.summary.data2016bysite.csv" in folder output - Brook Trout (BT) only.  Need to find out what the distinction is among the formulations.  
   - We found that the amec functions scale biomass by area so no need to do this (speculation - I think that AMEC functions calculate density, i.e., the (number of fish)/area and then biomass is density*avg_weight).
   - We found that Kristin's figures, are the mean of the scaled biomass for sites - the question is, is this the right way to summarize things.  Answer: no I think.  Better to summarize by year over teh BACI.


## Figures
- The area estimates are from \Raw data\SealCoveHabitat2016.xlsx and SealCove River Survey 2015.xlsx (same folder).  SealCoveHabitat.2016 also has wetted depth, bankfull width, length, and depth. SealCove River Survey 2015.xlsx has averagewidth, area, Meanpool depth for each pool/riffle and much of what is in Table 1 for 2015/2016.  

- Kristin also sent me two files: "Mean_Bio_SC.csv" and "Mean_Den_SC.csv" which are derived files generated in "mean_stderrors_andplots.R" from file "edited_cs_estimates_by_site.csv".  These produce Figure 4 and 6 for BT and BTYOY (note that the data are right but these aren't exactly the figures in the ms - these have colour and 4 pannels)  
    - I have modified these to show the pools v riffes and so that analyses in text can be compared to a graph (in mean_stderrors_andplots_KL.R)

- The output of the amec functions with the "by type" data is the total biomass in the various treatments, i.e., compensation, downstream control, upstream control

- See notes on Fig 8.  This plot is produced in "Pool_estimates_and_plots.R" with object "BTPoolBio_SC"

- Table 2 is identical to Mean_Bio_SC.csv and Mean_Den_SC.csv: I checked and all of these values correspond - I think its written in the notes the files and data sets.

## Analyses
- Models were all done in GLM_Gamma_SealCove_DCJan2017.R and in gamma_glms_all_species.R.  These were split out by pools and not pools (i.e., riffles) because there are no pools in the control treatment and therefore, any interaction term will yield a NA. For BT, BTYOY, ASYOY, these results correspond perfectly or very close.  The exception seems to be BT density.  However, for AS, there are zeros and gamma isn't appropriate.  
- Now, all are in glmm_data.R, glmm_biomass_models.R, glmm_density_models.R, and glmm_anova.R (see below).  

## Files
glmm_anova.R is a bunch of figures that I have somewhat redone in glmm_biomass and glmm_density.

glmm_anova.R and mean_stderror_andplots_KL.R are largely redundant.  The difference is that glmm_anova.R has figures for LUNKERS and dot plots showing variation while mean_stderror_andplots_KL.R produces the figures in functions and has baci.plots.

## BACI  
The study design, at least on face value is an internally replicated BACI , i.e., its replicated along one stream.  However, it has gaps.  First, there are only two years of pre-impact.  This is not awful but obviously, more would have been better.  The bigger problem is that there is only one pond and one riffle in the Before period and both were destroyed.  

Therefore, for riffles, this is a BACI although its somewhat weak on the Before:Control side and only for the upstream.  

For pools, this study is really more of a Before:After with a little Before.  Therefore, we can't do a BACI and are limited to a one-way ANOVA type model.  

At a broader scale of how generalizable are these results, I believe that this is not pseudoreplication as long as we do not extrapolate the results of the study too far.  The results can probably apply to most streams of similar size in the eastern boreal forest.  Don't want to extrapolate to the Exploits.  

Note that its certainly possible but very logistically difficult and expensive to do an internally replicated BACI on multiple streams over this time period. This does not include allowing for the Impact to be coordinated across multiple sites. 

# Speculations
- Is Kristin's way right, i.e., take an average of all the pools/riffles?   Yes, I think so.  See justification in Cote code (Note - put where this is - can't find it now; also, i've re-thought this - see below options).  
    - Kristin put the values in original values from the AMEC code in "output_cs_eachsppbysite.xlsx".   The mean and variance in Mean_Bio_Sc are simply the mean and variance of the year, species, and type (destroyed v control) but there is also sample size. 

Options:  
    -  Proceed with current analysis (e.g., mean of Year, pool, time, trt - BT_estimates_by_site).  Simple but does not take variance into account.  Probably the best for teh graphs and means I don't have to change anything.  
    -  As above but use BT_estimates_by_site but weight by variance.  Don't really like this because this is not really the variance but simply the variance of several means with the variance unaccounted for.   
    - Use each site but without variance.  This is also simple to implement.  
    - Use each site but weight with variance.  This is the most robust approach but variances are very small - not sure if its worth it. The variances here could be derived from the CIs which are based on lm.  
    Solutions: OK, I talked to Fifield and using option #3 (use each site without variance) we did a Zuur type exercies buidling on what I had done.  Basically glm -> gls -> lme -> glmm.  glmmTMB seems to take care of the homogeneity of variance and normality issues that occur in glm, gls, and lme.
    
Other issues (Dave Cote):    
    - Gamma is fine for BT, BTYOY, and ASYOY but not for AS.  They have used Poisson which is not really quite right, i.e., a discrete distribution for non-discrete data. 
    Talked this over with Paul Regular and Dave Fifield - could do a hurdle model.  The reason for a hurdle (delta) model is that Keith Clarke believes that these are true zeros.  
    - Independence issues - see Zuur and Dave.  
        - Dave F showed me how to look at Temporal Independence and Spatial independence using package DHARMa (https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html#workflow-in-dharma).  We did Temproal by year and there are no issues.  Spatial will require lat/long converted to UTM.  However, i'm not sure how the "Stations" in BT_estimates_by_site correspond to those on the map (see below).  See glmm_biomass_models.R, glmm_density_models.R, and glmm_anova.R.  
Data issue:  note that coordinatesA has station 45 which only exists in 1993 and seems to be a combination of 4 and 5. Up until now, I have been treating it as 4.  I think its best to delete it as we really don't know what it is and it seems to have multiple areas.  
        
# How I decided on the final approach

There are a lot of ways to tackle this simple BACI design.  I agree with Dave Cote's general approach, i.e., that these are not OLS type models and that something more complex is required.  The key items are distribution, assumptions (homegeneity of variance, independence), whether a random effect is required, how to deal with zeros, and finally, diagnostics.  The table below summarizes the various approaches.  

## Linear Model
Basically, GLM can't handle random effects (for repeated measures - the way it was done was to take a mean which loses information, i.e., variance) and LMM can't handle non-Gaussian distributions.  So this leaves GLMM.

Note that GLMMs (in glmmTMB) have four components, the conditional model, the distribution, the zero inflation model, and the dispersion formula.  The conditional model will be either a BACI or one-way ANOVA type as appropriate for these data.  The distribution will be Gamma (but this can't handle zeros), a Gamma hurdle model, or Tweedie.  See below for discussion of zeros and the dispersion formula.  

## Random effects

**See notebook, date 2024-05-23**  

At some point, I decided to do repeated measures on Year rather than Station.  I cannot recall the rationale but it does seem to make a difference.  So, I spent the better part of 3 days thinking about this and it recalls the hell of PhD days trying to figure this out for Chapter 4 (see Crossed vs Nested).

Remember: nested and crossed are aspects of the study design and affect the model structure while fixed and random are variable specific and are chosen as such by the researcher (whether the researcher has done so correctly or can justify it is another matter).

So, the good news is that glmmTMB is a reasonable package to use for BACI, e.g. Rasswiler2021 - Ecol Appl (code on Github  - https://github.com/dkokamoto/Ecol_Apps_BACI/blob/v0.3.1-alpha/Code/Functions.R.  Note that they have site and Id as random effects and do an autoregressive approach - ar1(time+0|Site). Wolfram 2018 also uses Site and Year.  There is also some flexibility in the approach - see Loughlin 2021 CJFAS who use mix models) who clearly explain their rationale for developing the model and choosing which terms are random and fixed.

I also found epower which is a Bayesian approach to power analysis for BACIs and has the clearest, most cogent outline of the nesting.

The bad news, is that this is a tough one because we don't have unlimited data and this is a "partial" nested, i.e., D1 and D2 were destroyed and C1-C9 are all in the after because they were created while D15 and D16 were added as afterthoughts.  The only fully crossed sites are C10-C12.  

Ruminations:  
Repeated measures on the observational unit equates to nesting, i.e., the unit is nested within a factor.  In the case of SC, the observational unit is the experimental unit, i.e., the station.  But station is not crossed with year.  Year applies to every station but not every station applies to a year, ergo, station is nested within year.  However, this applies to Treatment and Time too.  1988-1989 are only in Before.  Note: I don't think this is true.  Repeated measures can be in a crossed design with subjects, repeatedly measured, assigned to the various experimental units.  Also, see Crossed vs. Nested below.

Still not clear why a random effect equates to repeated measures , e.g., (1|Year) is supposedly the way to account for repeated measures but its also the code for random effect.  So, is repeated measures really just a random-intercept model?? - Yes, I think that this is right and its because of the CV matrix - check that this is right in Zuur.  Answer: I think its because repeated measures tries to account for variation within-subject since these repeated measures aren't replicates and shouldn't be treated as such (classic psuedo replication).  A random intercept effectively is the same thing - the intercept varies for each level of the random factor which removes this variation (**The other way to deal with non-independence of a subject’s residuals is to leave the residuals alone, but actually alter the model by controlling for subject.  When you control for subject as a factor in the model, you literally redefine what a residual is.  Instead of being the distance between a data point and the average for everyone, it’s the distance between a data point and the mean for that subject.** https://www.theanalysisfactor.com/repeated-and-random-2/).  Mixed models are obviously much more flexible because you can do random slopes and random intercepts/slopes.  

My thought is that I could nest things or just have site as a repeated measure within year?
Can't nest Year/Time and Station/Treatment due to degrees of freedom issues

See scratch_pad_rdmEffects - basically, I tried a whole bunch of nested random and nested random and straight random approaches.  The problem is that the more of these you stick in, the less variance to go around and things aren't significant.  

Websites:
Code and rationale for adding Year and Station as random effects and either interaction or nesting.
https://stackoverflow.com/questions/63360751/specifying-random-effects-for-repeated-measures-in-logistic-mixed-model-in-r-lm

For how to code nested v crossed effects: https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified

Same variable in fixed and random component with justification plus ruminations on nested.
https://stats.stackexchange.com/questions/398444/how-to-correctly-model-repeated-measures-random-effects-in-a-linear-mixed-effect

Bolker says you can use a variable as fixed and random
https://stats.stackexchange.com/questions/235199/how-to-build-a-generalized-linear-mixed-model-with-repeated-measures-in-r

## Crossed vs Nested  
From Bolker_14-Fox-Chap13.pdf:
What about the interaction between two random effects? Here we have to specify whether the two effects are nested or crossed. If at least one of the levels of each effect is represented in multiple levels of the other effect, then the random effects are
crossed; otherwise, one is nested in the other.  

Similarly:  
"a factor is nested within another factor if it's levels belong to one and only one level of the other one" - Robert Long  
https://stats.stackexchange.com/questions/525360/linear-mixed-model-with-partially-crossed-random-effects



## Zuur's approach (2009) pg 
- Fit a "beyond" optimal fixed effects model (over fit the model?)  
- Using this model, find the optimal random component - compare using REML (see below)  
- Find optimal fixed structure using ML  
- present with REML

I think that I really need only do 2 & 4.  I have a fixed model that I want to test and the random compoenent is know. The only thing that I need to worry about is if the diagnostics are bad.  
Note: REML provides better esimates of the variance components and standard errors than does ML  But REML can't be used to compare models with different fixed effects.  For this, you need ML.  While very important, I don't think that this is relevant since I generally use REML to compare dispersion models and am only looking at parameter estimates.
https://stats.stackexchange.com/questions/116770/reml-or-ml-to-compare-two-mixed-effects-models-with-differing-fixed-effects-but/116796#116796  

Also, I don't think I ever compared models with different fixed effects using AIC.  The only thing I changed was the distribution and the dispersion formula.  But I did add Year to the best model.  

From Zuur:   
Two models with nested random structures cannot be done with ML - use REML. I could have this
Models with nested fixed effects structures must be done with ML. I could have this but the whole intent of a BACI is to test the interaction, ergo I don't have nexted fixed effects. 
But websites say different fixed effects.https://stats.stackexchange.com/questions/116770/reml-or-ml-to-compare-two-mixed-effects-models-with-differing-fixed-effects-but/116796#116796  
Bolker:
"The reason is that REML estimates the random effects by considering linear combinations of the data that remove the fixed effects. If these fixed effects are changed, the likelihoods of the two models will not be directly comparable"

## Zeros  
- 1. inflate the zeros slightly
- 2. fall back on lmm with a non-gamma distribution
- 3. zero inflated or hurdle
- 4. tweedie

Inflating the zeros is probably not awful but not great (see Zuur et al. 2009).  Using an improper distribution isn't a great idea.  Zuur et al. 2009, pg XXXXXX explains the difference between zero-inflated and hurdle models; the former is real/structural, the latter is real.  See Sean Anderson page for great explanation: https://seananderson.ca/2014/05/18/gamma-hurdle/ - see also Google Chrome, stats, zi-hurdle


On consultation with Keith Clarke, the zeros are probably real, i.e., structural and therefore, zero-inflated are not appropriate.  Hurdle models (also called delta and maybe also called zero-augmented) are appropriate.  A "manual" hurdle model was very helpful for getting me to understand how hurdle models work, i.e., what process produces the zeros.  It looks like sdmTMB can handle these but so can glmmTMB.  However, for sdmTMB, its not clear to me exactly how to do the diagnostics and these are specifically for spatial models.   
On the principle of avoiding statistical puritanism and producing a model that is "good enough", I think a hurdle Gamma (ziGamma) or Tweedie distributed glmm in glmmTMB is the best balance of accounting for zeros and still having diagnostics at least for the BTYOY.  Not sure about AS and ASYOY.  

This website advises that zi models are a mix while hurdle models have only structural zeros. Clarke suggested in an email that these are structural zeros as larger conspecifics will eat the smaller fish, ergo use a hurdle model.
https://biol609.github.io/lectures/13_zinf.html#53_the_error_generating_process  

Some thoughts on Tweedie dist:   https://stats.stackexchange.com/questions/582124/when-should-one-use-a-tweedie-glm-over-a-zero-inflated-glm  

glmmTMB family help file "a modified version of Gamma that skips checks for zero values, allowing it to be used to fit hurdle-Gamma models"  

Bolker suggests no difference because a ziGamma doesn't make sense except as a hurdle model: https://stackoverflow.com/questions/65745148/is-there-a-difference-between-gamma-hurdle-two-part-models-and-zero-inflated-g  

### fitted values for zi
https://discourse.mc-stan.org/t/mathematical-notation-for-a-zero-inflated-negative-binomial-model-in-brms/21066/13
https://www.montana.edu/rotella/documents/502/Prob_odds_log-odds.pdf

1/(1 + exp(zi)) = q or event of a zero
1/(1 + exp(-zi)) = p (1-q) or the probability its **not** a zero 
With the notation, i've used, zi is applied equally to all observations.

## syntax  
From https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf
ziformula = ~1 applies a single zero-inflation parameter to all observations. Default is ziformula ~0 which excludes zero inflation.  
In same text, they use truncated negative binomial and ziformula =~. (not sure what this means).  

In this text "https://backend.orbit.dtu.dk/ws/portalfiles/portal/154739064/Publishers_version.pdf", they also use truncated distributions and zi = ~spp which suggests to me that the zero inflation varies by species.  

From glmmTMB help file, search under family:
ziGamma
a modified version of Gamma that skips checks for zero values, allowing it to be used to fit hurdle-Gamma models.  So, ziformula = ~1 is right for gamma distributed hurdle models!!!!!!!!!!!!  

Note that the cannonical link for ziGamma is inverse.  I think that I just used log because I saw it and its easier to think this way.  Bolker also used it here: https://stackoverflow.com/questions/65745148/is-there-a-difference-between-gamma-hurdle-two-part-models-and-zero-inflated-g

On nesting syntax:
A model of nested random effects
(block within site) could be 1|site/block if block labels are reused across multiple sites, or (1|site) + (1|block) if the nesting structure is explicit in the data and each level of block only occurs within one site. A model of crossed random effects (block and year) would be (1|block)+(1|year). (https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf)


https://psyteachr.github.io/ug3-stats/linear-mixed-effects-models-with-crossed-random-factors.html

Very clear explanation of lmer4 syntax and relates terminology between approaches, e.g., paired t-test in mixed model terminology.  Also, advocates teh "maximal random effects" or "design-driven" approach in which you account for all sources of non-independence introduced by repeated sampling.
The best way to think about this bracketed part of the formula (1 + x | subject_id) is as an instruction to lme4::lmer() about how to build a covariance matrix capturing the variance introduced by the random factor of subjects.

> (fm2 <- lmer(diameter ~ 1 + (1|plate) + (1|sample), Penicillin))




## Other things...
Why didn't you combine this all into one big model with Pool as a factor?  Lazy but mostly lack of data and concerns about interpretation and lack of power.  

Year effect was included just as a covariate to take care of residual patterns but is of no interest.  Further, in the case of BTYOY-np and AS-NP, the Time parameter is negative suggesting Before > After but the Year term was negative.  Upon inspection, this was generally due to most of the After values being less than the Before values (so mean After < mean Before) but there were a few sites After that were higher than the Before and this probably creates a negative trend.  So, rather than explain something that's not of interest and causing confusion, I just removed it. 

# Model approaches and packages
```{r, eval=T,prompt=T, comment = F}

datatable(tab1, rownames = F, class = 'cell-border stripe', height = 80,  options = list(dom = 't', searching = F, pageLength = 30, autoWidth = TRUE, scrollY = F, 
                                                                                          columnDefs = list(list(className = 'dt-center', targets = 1:5)), 
                                                                                         initComplete = JS("
                        function(settings, json) {
                          $(this.api().table().header()).css({
                          'font-size': '20px',
                          });
                        }
                    "))) %>%
  formatStyle(columns = colnames(.$x$data), `font-size` = "20px")
```

Good website on model syntax https://stats.stackexchange.com/questions/477338/reading-multilevel-model-syntax-in-intuitive-ways-in-r-lme4  

Note that Sean Anderson has developed sdmTMB which Krista Baker is using.  I think that this is a very good package but not needed because its very focused on spatial distribution and indeed, was made for species distribution models (hence "sdm").  glmmTMB is the more widely used package so stick with that for now.

For curvilinear models:  
#https://stackoverflow.com/questions/24192428/what-does-the-capital-letter-i-in-r-linear-regression-formula-mean 

# Dispersion formula
INT is for Interaction, not intercept.  dispformula ~ Int is therefore to account for differences in standard errors among the different interaction levels.  This works for non-pools because the non-pools have the full BACI design.  The dispformula changes to ~ Time for pools and ~ Lunkers for the LUNKER analysis because there were no pools as controls (either before or after).  

Note: The conditional model fits the mean, the dispersion models the variance via a log-link(see help("glmmTMB")). https://stats.stackexchange.com/questions/615196/which-one-conditional-or-dispersion-model-is-the-final-result-in-glmmtmb  

Note that I do not really understand the impact that this has on model outputs, especially fitted values.  I can reconstruct fitted values for a lm, glm, and glmm and for zero-inflated (hurdle) (see glmm_density.R or glmm_biomass.R - basically, fitted values = exp(fixed + random effects) x 1/1+exp(coefficients$zi) where fitted are coeffcients x design matrix) but not for  dispersion.  Remember that mixed models have an additional term while zero-inflated(hurdle) have an extra equation to model the zeros v non-zero values - again.  For dispersion, I assume that its just bringing in another term in the main model and it affects the variance - perhaps the impact is on confidence intervals but this requires matrix multiplication (see scratch_pad_glm.R) for mixed effects.  

**Some of the previous paragraph is wrong**.  I did a quick and fruitful search on ChatGPT which suggests that the dispersion model only modifies the variance and has no influence on the fitted values.  I went back and checked and the models with a dispersion formula do indeed match the fitted values by adding the fixed, random, and zi values together.  So i'm not sure where I went wrong on this but it is great news.  I think that the dispersion formula will influence the variance.  I should figure out how: the place to start is glmm_biomass_models.R, L 1558.  

See also Zuur et al. 2009, pg 285 for reconstructing fitted values.  

# Diagnostics
I have spent a great deal of time looking at the diagnostics and for some tests, I can't get a model that doesn't violate at least some of the assumptions at least a bit.  Sometimes, the model won't converge if I make it too complicated.  In other cases, fixing one diagnostic makes causes other diagnostics to go bad.  I talked to Krista Baker and her suggestion was to document what was done and present the results.  If there were diagnostics that were violated, then you did your best and just need to temper the interpreations accordingly.   
So the options are:  
1. Diagnostics are good - proceed  
2. Diagnostics are poor but p-value is far from alpha - proceed (light grey).  
3. Diagnostics are poor but p-value is near alpha - present with qualifier (dark grey).  

For how to intepret resids see:
https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html#workflow-in-dharma 

## Temporal autocorrelation
https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html#workflow-in-dharma for how to intepret resids

## Spatial autocorrelation
Scaled residuals  
https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html
To interpret the residuals, remember that a scaled residual value of 0.5 means that half of the simulated data are higher than the observed value (blue), and half of them lower (red).

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

## Moran's I
https://gis.stackexchange.com/questions/99660/interpreting-morans-i-results  
You interpret the hypothesis test the same way you do any others. That is, you fail to reject the null hypothesis that there is no spatial auto-correlation in the values of year2009 for this sample.

https://www.nku.edu/~longa/geomed/ppa/doc/globals/Globals.htm#:~:text=The%20expected%20value%20of%20Moran's,which%20neighboring%20values%20are%20dissimilar.  
The expected value of Moran’s I is -1/(N-1). Values of I that exceed -1/(N-1) indicate positive spatial autocorrelation, in which similar values, either high values or low values are spatially clustered. Values of I below -1/(N-1) indicate negative spatial autocorrelation, in which neighboring values are dissimilar.

# 2024-03-14
Although long suspected, it is now obvious that I was not functioning at a very high level in the fall.  So, upon returning, I think that i've solved a few problems.  
- An ANCOVA can help resolve some of the temporal patterns.   
- For Pools and LUNKERS, it makes no sense to look for spatial patterns as there are only 5 pools (1 before, 4 after) and there is basically a 50% chance of the pools near each other having the same residual sign.  Instead, I examined all of the biomass and density plots and there doesn't seem to be much of a problem.  It seems clear that LUNKER pools are good for adult brook trout (biomass and density) but really not much help for AS. For YOY, at first glance, there seems to be an inverse relationship between adult salmonids and YOY.  Pool 3 has few adults and far and away the most YOY, so really its a site effect and not very interesting.   
- After considerable effort trying to relate the values of the various Stations to the residual values, I realized that the data sets that I generate in glmm_data already have lat/longs while the actual coords.* data sets are in a different order.  Therefore, it was inappropriate to use coords.* in the testSpatialAutocorrelation function as this mixes up the order. After considerable effort, I have resolved this issue. 

- In general, the spatial autocorrelation is not great but:  
    - the Moran's I are not significant (likely due to low power),  
    - the plots don't look awful,  
    - the p-values are often not close to alpha  
Therefore, conclude that reasonable inferences are being made and get on with it!!!!  
- A final problem was that in the original projection, the eastings are stretched out and it distorted the spatial relationships among the Stations.  I fixed this by modifying the xlim.  


# MS considerations
- How to present - current ms falls short.


# A note on variable types
I ran into a little problem with Year.  Initially, I converted the factor variable Year to numeric using as.numeric(as.character(Year)).  This was fine as a linear term but what I had forgotten was that in a formula, for a quadratic, you need I(Year)^2.  So, alot of the work needed to be retested.

# Fading plots  
I like Cote's fading plots.  They get at the idea that the effect is working in the long term which is good.  

However, I don't think that these are doing what Cote intended.  He's subsetting by Time == "After" and Treatment == "Impact" and re-running the analysis with YOS (year of study) and Pool as variables.  Then, he's generating predicted values, bound them to the data set and subsetted by "pool" or "riffle" again before plotting.:  

I don't agree with this approach. Aside from the original issues with using glm (see above), its creating a new model, conflating the pools/riffles, and using these new parameter estimates to say something about the effect over time.  I think you should use the values from the original model and use the coefficients for the fixed and random effects for just the After:Impact to get at the fading effect. See scratch_pad_glm for all the rationale and justification for why this works.  

# The story

For BT, there are more fish and higher biomass in pools than riffles.  There is a general increase in the pools but this is driven to some degree by 2016 - suggests more fish.  The riffle controls oscilate without trend upstream and downstream while density is dome-shaped downstream but increasing upstream suggesting bigger fish.  

BTYOY there are more fish in the riffles than the pools.  BTYOY generally decrease in biomass and density for all although downstream is dome-shaped.  Perhaps this is due to canabalism.

AS may have a few more fish and higher biomass in the riffles.  Density and biomass oscilate without trend in the pools but density increases in the treatment riffles while biomass levels off.  Both biomass and density seem to increase in teh controls.

ASYOY there are more fish in the riffles than the pools. The original pools had far more ASYOY than the created pools which generally had low ASYOY.  They also had more fish than the riffles.  There is a general decreasing or domeshaped trend for the riffles.

Lunkers appear to be good for BT but for AS, there is no effect.  For YOY, pool C3 is good but the rest are not.  Again, predation may be a factor.  Indeed, C3 seems to be a very poor pool for BT and this may be the reason its good for YOY.  C3 is OK for AS but biomass is 50 here whereas its close to 500 for the BT and this is the worst pool for BT - other pools are > 1000 or > 2000.

Also, there appears to be some relationship between adult and YOY but it is strongest for BT in pools.  But this is testing hypotheses after looking at the data and therefore, a post-hoc hypothesis. But Clarke or Kristin might have thought of this before hand so bring it up.

Fading plots suggest that there is little change over time, i.e., the restoration has worked in the long term.  

Analytical problem with AS and ASYOY density in pools.  

Basically, the density and biomass for AS in pools looks the same and this is confirmed by the stats for biomass but not for density.  Density is a ziGamma with dispersion while biomass is basic model with Tweedie.  Tweedie doesn't work for density due to convergence issues.  

But for ASYOY, the graphs look very different - pools are much higher before than after.  This is confrimed by the stats for biomass but not density.  With density, a quadradic term for year was needed to get the resids to look ok and this may have soaked up all the variance.  

# Meeting for early May with Clarke and Kristin


# To do
- Fig 7 (large fish plots) where was this done - need the file: haven't received these.

TEST